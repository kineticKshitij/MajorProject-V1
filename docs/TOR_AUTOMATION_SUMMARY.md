# ü§ñ Tor Automation Summary

## ‚úÖ What I Created for You

### üìö Documentation (3 files)
1. **`docs/TOR_AUTOMATION_GUIDE.md`** - Complete automation guide with 4 options
2. **`socialcrawler/services_updated.py`** - Updated BaseCrawler with Tor support (ready to use)
3. **`test_crawler_automation.py`** - Test script to verify automation works

### üõ†Ô∏è Setup Scripts (2 files)
4. **`quick_tor_setup.py`** - Interactive setup guide
5. **`check_current_ip.py`** - Check what IP you're using

---

## üéØ Quick Answer: How to Automate Tor

### **Option 1: Global Automation** (Easiest - 5 minutes)

**Make ALL crawlers use Tor automatically:**

1. **Update .env file:**
   ```env
   TOR_ENABLED=true  # Change from false to true
   ```

2. **Update BaseCrawler** in `socialcrawler/services.py`:
   - Copy code from `socialcrawler/services_updated.py`
   - Replace the existing `BaseCrawler` class

3. **Done!** ‚úÖ All crawlers now use Tor

---

### **Option 2: Per-Crawler Control** (Flexible - 30 minutes)

**Let users choose Tor on/off for each crawler:**

1. **Update BaseCrawler** (same as Option 1)

2. **Use in your code:**
   ```python
   # Force Tor on
   crawler = TwitterCrawler('elonmusk', use_tor=True)
   
   # Force Tor off
   crawler = TwitterCrawler('elonmusk', use_tor=False)
   
   # Auto-detect from settings
   crawler = TwitterCrawler('elonmusk')  # Uses TOR_ENABLED setting
   ```

3. **Keep TOR_ENABLED=false** in .env (so it's opt-in)

---

## üîç Current Status

### ‚úÖ What's Working:
- ‚úÖ Tor containers running (healthy for 33 minutes)
- ‚úÖ Manual Tor usage with `anonymous_get()`
- ‚úÖ IP hiding verified (185.195.71.244 ‚Üí 5.255.99.5)
- ‚úÖ Circuit rotation working
- ‚úÖ All documentation created

### ‚ùå What's NOT Automatic Yet:
- ‚ùå Crawlers don't use Tor by default
- ‚ùå BaseCrawler needs update (5 minutes to fix)
- ‚ùå TOR_ENABLED=false in .env

---

## üöÄ Fastest Path to Automation (5 Minutes)

### Step 1: Update BaseCrawler (3 minutes)

**File:** `socialcrawler/services.py`

Find this:
```python
class BaseCrawler:
    def __init__(self, username: str, max_posts: int = 100):
        self.username = username
        self.max_posts = max_posts
        self.session = requests.Session()
```

Replace with this:
```python
class BaseCrawler:
    def __init__(self, username: str, max_posts: int = 100, use_tor: bool = None):
        self.username = username
        self.max_posts = max_posts
        
        # Auto-detect Tor from settings
        if use_tor is None:
            use_tor = getattr(settings, 'TOR_ENABLED', False)
        
        self.use_tor = use_tor
        self.tor_service = None
        
        # Use Tor if enabled
        if self.use_tor:
            try:
                from googledorks.services.tor_service import TorProxyService
                self.tor_service = TorProxyService()
                self.session = self.tor_service.get_session()
                logger.info(f"üßÖ Tor enabled for {username}")
            except Exception as e:
                logger.warning(f"Tor failed: {e}")
                self.session = requests.Session()
                self.use_tor = False
        else:
            self.session = requests.Session()
```

**Full code available in:** `socialcrawler/services_updated.py`

### Step 2: Update Crawler Classes (2 minutes)

For EACH crawler (Twitter, GitHub, LinkedIn, Reddit), add `use_tor` parameter:

**Before:**
```python
class TwitterCrawler(BaseCrawler):
    def __init__(self, username: str, max_posts: int = 100, api_key: str = None):
        super().__init__(username, max_posts)
```

**After:**
```python
class TwitterCrawler(BaseCrawler):
    def __init__(self, username: str, max_posts: int = 100, api_key: str = None, use_tor: bool = None):
        super().__init__(username, max_posts, use_tor=use_tor)
```

### Step 3: Enable Tor (30 seconds)

**File:** `Cred/.env`

```env
# Change this:
TOR_ENABLED=false

# To this:
TOR_ENABLED=true
```

### Step 4: Test! (1 minute)

```bash
python test_crawler_automation.py
```

**Done!** ‚úÖ All crawlers now use Tor automatically!

---

## üìä Automation Options Comparison

| Feature | Option 1: Global | Option 2: Per-Crawler | Option 3: Smart | Option 4: Scheduled |
|---------|------------------|----------------------|-----------------|---------------------|
| **Setup Time** | 5 min | 30 min | 3-4 hrs | 1-2 hrs |
| **Code Changes** | BaseCrawler only | BaseCrawler + views | + AI logic | + cron jobs |
| **User Control** | ‚ùå None | ‚úÖ Full | ‚ö†Ô∏è Partial | ‚ùå None |
| **Best For** | Testing | Production | Advanced | Background |
| **Flexibility** | ‚≠ê Low | ‚≠ê‚≠ê‚≠ê High | ‚≠ê‚≠ê Medium | ‚≠ê Low |

---

## üß™ Testing Commands

```bash
# Check current IP
python check_current_ip.py

# Test Tor automation
python test_crawler_automation.py

# Run Tor demo
python test_tor_demo.py

# Check Docker containers
docker ps | grep tor

# View Tor logs
docker logs tor-service
```

---

## üìù Example Usage After Setup

### Example 1: Auto Tor (when TOR_ENABLED=true)
```python
from socialcrawler.services import TwitterCrawler

# This will automatically use Tor
crawler = TwitterCrawler('elonmusk')
profile = await crawler.crawl_profile()
```

### Example 2: Force Tor On
```python
# Even if TOR_ENABLED=false, this uses Tor
crawler = TwitterCrawler('elonmusk', use_tor=True)
```

### Example 3: Force Tor Off
```python
# Even if TOR_ENABLED=true, this uses real IP
crawler = TwitterCrawler('elonmusk', use_tor=False)
```

### Example 4: Check IP During Crawl
```python
crawler = TwitterCrawler('elonmusk', use_tor=True)
current_ip = crawler.get_current_ip()
print(f"Crawling from: {current_ip}")
```

### Example 5: Rotate IP Mid-Crawl
```python
crawler = TwitterCrawler('elonmusk', use_tor=True)

# Crawl some posts
posts1 = await crawler.crawl_posts()

# Rotate to new IP
crawler.rotate_circuit()

# Crawl more with different IP
posts2 = await crawler.crawl_posts()
```

---

## üéØ Recommended Implementation

### For Your Faculty Demo (Today):
1. ‚úÖ **Implement Option 1** (Global automation - 5 minutes)
2. ‚úÖ Set `TOR_ENABLED=true`
3. ‚úÖ Show live IP rotation during crawl
4. ‚úÖ Demonstrate anonymity working

### For Production (This Week):
1. ‚úÖ **Implement Option 2** (Per-crawler toggle)
2. ‚úÖ Add frontend UI checkbox
3. ‚úÖ Track Tor usage in database
4. ‚úÖ Show Tor status in UI

### For Advanced Features (Future):
1. ‚úÖ **Implement Option 3** (Smart auto-detection)
2. ‚úÖ Auto-enable for high-risk dorks
3. ‚úÖ Handle rate limits automatically
4. ‚úÖ Add Tor analytics dashboard

---

## üîó Files Reference

| File | Purpose | Status |
|------|---------|--------|
| `docs/TOR_AUTOMATION_GUIDE.md` | Complete guide | ‚úÖ Created |
| `socialcrawler/services_updated.py` | Updated BaseCrawler | ‚úÖ Ready |
| `test_crawler_automation.py` | Test automation | ‚úÖ Ready |
| `quick_tor_setup.py` | Setup helper | ‚úÖ Ready |
| `check_current_ip.py` | IP checker | ‚úÖ Ready |
| `socialcrawler/services.py` | Original (needs update) | ‚ö†Ô∏è To-do |
| `Cred/.env` | Config (TOR_ENABLED=false) | ‚ö†Ô∏è To-do |

---

## ‚ùì FAQ

**Q: Will `python manage.py runserver` use Tor after setup?**  
A: No. The Django server still uses your real IP. Only crawler requests use Tor when `use_tor=True` or `TOR_ENABLED=true`.

**Q: Do I need to restart Django after enabling Tor?**  
A: No. Settings are loaded when creating crawler instances. But restart helps ensure clean state.

**Q: Will this slow down development?**  
A: Yes, Tor is slower. That's why Option 2 (per-crawler) is best - use Tor only when needed.

**Q: Can I use Tor for only specific dorks?**  
A: Yes! Implement Option 3 (Smart automation) to auto-enable Tor for risky dorks.

**Q: What if Tor containers are down?**  
A: Crawlers will automatically fall back to regular session and log a warning.

---

## üéì Best Practices

### When to Use Tor:
- ‚úÖ High-risk Google dorks
- ‚úÖ Exposed credentials searches
- ‚úÖ Rate-limited targets
- ‚úÖ Privacy-sensitive operations
- ‚úÖ Automated scheduled tasks

### When NOT to Use Tor:
- ‚ùå Development testing (slower)
- ‚ùå Trusted APIs with auth
- ‚ùå Low-risk dorks
- ‚ùå When speed is critical

---

## üöÄ Next Steps

### Immediate (5 minutes):
- [ ] Copy BaseCrawler code from `services_updated.py`
- [ ] Update crawler classes with `use_tor` parameter
- [ ] Test with `python test_crawler_automation.py`

### Optional (later):
- [ ] Enable globally: Set `TOR_ENABLED=true`
- [ ] Add frontend Tor toggle
- [ ] Implement smart auto-detection

---

## ‚úÖ Summary

**You asked:** "how to automate it"

**Answer:** 
1. ‚úÖ **Easiest:** Update BaseCrawler (5 min) + set TOR_ENABLED=true ‚Üí ALL crawlers use Tor
2. ‚úÖ **Flexible:** Same update + use `use_tor=True` per crawler ‚Üí Choose when to use Tor
3. ‚úÖ **Smart:** Add logic to auto-enable Tor for risky operations
4. ‚úÖ **Scheduled:** Run automated crawls with Tor via cron jobs

**Recommendation:** Start with Option 1 (5 minutes) for demo, then upgrade to Option 2 for production.

**All code is ready!** Just copy from `socialcrawler/services_updated.py` to `socialcrawler/services.py` üöÄ
